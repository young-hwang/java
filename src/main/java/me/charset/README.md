# 컴퓨터와 데이터

개발자가 데이터를 다룰 때는 크게 0101로 되어 있는 바이너리 데이터(또는 byte 기반의 데이터)와 "ABC", "가나다"와 같은 문자로 되어 있는 텍스트 데이터를 다룸

텍스트 데이터와 문자 인코딩의 원리와 같은 기본 이론을 확실히 하자

컴퓨터의 메모리는 반도체로 만들어져 있는데 이는 수많은 전구들이 모여있는 것과 같음

이 '전구들'은 사실 트랜지스터라고 불리는 아주 작은 전자 스위치이다

각 트랜지스터는 전기가 흐르거나 흐르지 않는 두 가지 상태를 가질 수 있어 이를 통해 0과 1이라는 이진수를 표현함

이 트랜지서터들이 모여 메모리를 구성함

흔히 말하는 RAM(Random Access Memory)은 이런 방식으로 만들어진 메모리의 한 종류임

컴퓨터가 정보를 저장하거나 처리할 때, 이 '전구들'을 켜고 끄는 방식으로 데이터를 기록하고 읽어 들임

이 과정은 매우 빠르게 일어나며, 현대의 컴퓨터 메모리는 초당 수십억 번의 데이터 접근을 처리할 수 있음

## 2진수

전구를 켜고 끈다는 것은 0과 1만 나타낼수 있는 2진수로 표현할 수 있음

- 전구를 끈다: 0
- 전구를 켠다: 1

숫자 0을 메모리에 저장한다면 메모리의 전구를 하나 끄면 되고, 숫자 1을 저장한다면 전구를 하나 켜면 됨

그렇다면 숫자 2나 3은 어떻게 표현하는가? 전구를 하나더 사용하면 됨

전구 1개는 단지 0과 1이라는 2가지를 표현할 수 있지만 전구 2개를 묶어서 사용하면 총 4가지를 표현할 수 있음

핵심은 컴퓨터는 사람과 같이 10진수 숫자를 이해하고 숫자를 메모리 저장하거나 불러오는 것이 아니다

전수의 상태만 변경하거나 확인할 뿐임

전구 1개와 같이 2가지만 표현할 수 있는 것을 1비트(bit)라고 함

**8bit = 1byte**

## 숫자 저장 예시

10진수 100을 컴퓨터에 저장한다면?

컴퓨터는 10진수를 이해하지 못함

2진수 `1100100`으로 변경해서 저장

## 음수 표현

음수를 표현해야 한다면 처음 1bit를 음수, 양수를 표현하는데 사용

8bit -> 256가지 표현

- 0과 양수만 표현하는 경우
  - 8bit 모두 숫자 표현에 사용
  - 0 ~ 255
- 음수 표현이 필요한 경우
  - 1bit는 음수와 양수를 구분하는데 사용, 너미지 7bit 숫자 범위 사용
  - 0 ~ 127(양수 표현시 첫 비트를 0으로 사용, 나머지 7bit로 128가지 0과 양수 숫자 표현)
  - -128 ~ -1(음수 표현시 첫 비트를 0으로 사용, 나머지 7bit로 128가지 음수 숫자 표현)

# 컴퓨터와 문자 인코딩

컴퓨터는 10진수를 2진수로 변경해서 메모리에 저장함

숫자가 아닌 문자는 어떻게 메모리에 저장될까?

10진수는 정해진 수학 공식을 사용하면 쉽게 2진수로 변환할 수있지만 문자 'A', 'B'를 2진수로 변경하는 수학 공식 같은 것은 없음

이런 문제를 해결하기 위해 초창기 컴퓨터 과학자들은 문자 집합을 만들고, 각 문자에 숫자를 연결시키는 방법을 생각함

|문자|숫자|
|:--:|:--:|
|A|65|
|B|66|
|a|97|
|b|98|

예를 들어 문자 'A'를 저장하면 컴퓨터는 문자 집합을 통해 'A'의 숫자 값 65를 찾고 65를 메모리에 저장(2진수로 변환해서 저장)

메모리에 저장된 문자를 불러올 때는 반대로 작동

메모리에 저장된 숫자 값 65를 불러온 후 문자 집합을 통해 문자 'A'를 찾아서 화면에 출력

- 문자 인코딩: 문자 집합을 통해 문자를 숫자로 변환하는 것
- 문자 디코딩: 문자 집합을 통해 숫자를 문자로 변환하는 것

## ASCII 문자 집합

각 컴퓨터 회사가 독자적인 문자 집합을 사용한다면, 서로 다른 컴퓨터 간에 문자가 올바르게 표시되지 않는 문제가 발생하게 됨

이러한 호환성 문제를 해결하기 위해 ASCII(American Standard Code for Information Interchange)라는 표준 문자 집합이 1960년도에 개발됨

초기 컴퓨터에서는 주로 영문 알파벳, 숫자, 키보드의 특수 문자, 스페이스, 엔터와 같은 기본적인 문자만 표현하면 충분

따라서 7비트를 사용하여 총 128가지 문자를 표현할 수 있는 ASCII 공식 문자 집합이 만들어짐

**제어 문자(0-31, 127)**

| 십진수 | 문자  |   설명    |
|:---:|:---:|:-------:|
|  0  | NUL | Null 문자 |
|  1  | SOH |  헤더 시작  |
|  2  | STX | 텍스트 시작  |
|  3  | ETX |  텍스트 끝  |
|  4  | EOT |  전송 끝   |
| ... |     |         |
| 27  | ESC | Escape  |
| 127 | DEL |   삭제    |

**출력 가능한 문자(32~126)**


|   십진수    |      문자       |   설명   |
|:--------:|:-------------:|:------:|
|    32    |               |   공백   |
|    33    |       !       |  느낌표   |
|    34    |       "       | 큰 따옴표  |
|   ...    | #$%&'()*+,-./ | 특수 문자  | 
| 48 ~ 57  |     0 ~ 9     |   숫자   |
| 58 ~ 62  |     :;<=>     | 특수 문자  |
|    63    |       ?       |  물음표   |
|    64    |       @       |  앳 기호  |
| 65 ~ 90  |     A ~ Z     |  대문자   |
|   ...    |               |        |
| 97 ~ 122 |     a ~ z     |  소문자   |
|   ...    |               |        |
|   126    |       -       |   틸드   |

- ASCII의 숫자는 10진수 숫자가 아니라 문자로 표현된 숫자
- ASCII의 숫자는 컴퓨터 입장에서는 그림으로 된 숫자

## ISO_8859_1

서유럽을 중심으로 컴퓨터 사용 인구가 늘어나면서, 서유럽 문자를 표현하는 문자 집합이 필요 해짐

**ISO_8859_1**

- 1980년도
- 기존 ASCII에 서유럽 문자의 추가 필요
- 국제 표준화 기구에서 서유럽 문자를 추가한 새로운 문자 규격을 만듬
- `ISO_8859_1`, `LATIN1`, `ISO-LATIN-1`등으로 불림
  - 8bit(1byte) 문자 집합 -> 총 256가지 표현 가능
  - 기존 7비트 ASCII(0-127)를 그대로 유지
  - ASCII에 128가지 문자를 추가함(주로 서유럽 문자, 추가 특수 문자들) 예) Á, Â, Ä, Å, À, Ã, Ă
- 기존 ASCII 문자 집합과 호환 가능

## 한글 문자 집합

한국에서도 컴퓨터 사용 인구가 늘어나면서 한글을 표현할 수 있는 문자 집합이 필요

**EUC-KR**

- 1980년도
- 초창기 등장한 한글 문자 집합(더 이전에 KS5601 있었음)
- 모든 한글을 담는 것 보다는 자주 사용하는 한글 2350개만 포함해서 만듬
- 한글의 글자는 아주 많기 때문에 256가지만 표현할 수 있는 1byte로 표현하는 것은 불가능
- 2byte(16bit)를 사용하면 총 65536가지 표현 가능
- ASCII + 자주 사용하는 한글 2350개 + 한국에서 자주 사용하는 기타 글자
  - 한국에서 자주 사용하는 한자 4,888개
  - 일본어 가타카나등도 함께 포함
- ASCII는 1byte, 한글은 2byte 사용
  - 영어를 사용하면 1byte를 한글을 사용하면 2byte를 메모리에 저장
- 기존 ASCII문자 집합과 호환 가능

**MS949**

- 1990년도
- 마이크로소프트가 EUC-KR을 확장하여 만든 인코딩
- 한글 초성, 중성, 종성 모두 조합하면 가능한 한글의 수는 총 11,172자
- EUC-KR을 "쀍", "삡"과 같이 드물게 사용하는 음절을 표현하지 못함
- 기존 EUC-KR과 호환을 이루면서 한글 11,172자를 모두 수용하도록 만든 것이 MS949
- EUC-KR과 마찬가지로 ASCII는 1byte, 한글은 2byte를 사용함
- 윈도우 시스템에서 계속 사용됨

## 전세계 문자 집합

전세계적으로 컴퓨터 인구가 늘어나면서 전세계 문자를 대부분 다 표현할 수 있는 문자 집합이 필요해짐

**문제**

- EUC-KR이나 MS949 같은 한글 문자료를 PC에 설치하지 않으면 다른 나라 사람들은 한글로 작성된 문서를 열어볼 수 없음
- 한 문서 안에 영어, 한글, 중국어, 일본어, 히브리어, 아랍어를 함께 저장해야 한다면?
- 1980년대 말, 다양한 문자 인코딩 표준이 존재했지만 모두 특정 언어 또는 문자 세트를 대상으로 했기 때문에 국제적으로 호환성 문제가 많음

**유니코드의 등장**

- 전 세계의 문자들을 단일 문자 세트로 표현할 수 있는 유니코드(Unicode) 표준이 1990년대에 도입됨
- 하나의 문제 세트에 전 세계 대부분의 언어를 넣어보자! -> Uni(Universal) -> 전 세계적인 코드
- 전 세계의 모든 문자와 기호를 하나의 표준으로 통합하여 표현할 수 있는 문자 집합을 만드는 것
- UTF-16, UTF-8의 시작
- 두 표준이 비슷하게 등장, 초반에는 UTF-16이 인기

**UTF-16**

- 1990년도
- 16bit(2byte) 기반
- 자주 사용하는 기본 다국어는 2byte로 표현, 2byte는 65536 가지를 표현할 수 있음
  - 영어, 유럽 언어, 한국어, 중국어, 일본어 등이 2byte를 사용
- 그 외는 4byte로 표현 4byte는 42억 가지를 표현할 수 있음
  - 고대문자, 이모지, 중국어 확장 한자등
- 단점: ASCII 영문도 2byte를 사용, ASCII와 호환되지 않음
  - UTF-16을 사용한다면 영문의 경우 다른 문자 집합보다 2배의 메모리를 더 사용
  - 웹에 있는 문서의 80% 이상은 영문 문서
  - ASCII와 호환되지 않는다는 점도 큰 단점 중 하나
- 초반에는 UTF-16이 인기, 이 시기에 등장한 자바도 언어 내부적으로 문자를 표현할 때 UTF-16을 사용함, 그래서 자바의 `char`  타입이 2byte 사용
- 대부분의 문자를 2byte로 처기하기 때문에 계산이 편리함

**UTF-8**

- 1990년도
- 8bit(1byte) 기반, 가변길이 인코딩
- 1byte ~ 4byte를 사용해서 문자를 인코딩
  - 1byte: ASCII, 영문, 기본 라틴 문자
  - 2byte: 그리스어, 히브리어 라틴 확장 문자
  - 3byte: 한글, 한자, 일본어
  - 4byte: 이모지, 고대문자 등
- 단점: 상대적으로 사용이 복잡함
  - UTF-16은 대부분의 기본 문자들이 2바이트로 표현되기 때문에, 문자열의 특정 문자에 접근하거나 문자 수를 세는 작업이 상대적으로 간담함
  - UTF-8에서는 각 문자가 가변 길이로 인코딩되므로 이런 작업이 더 복잡함
- 단점: ASCII를 제외한 일부 언어에서 더 많은 용량 사용
  - UTF-8은 ASCII 문자를 1byte로 비ASCII 문자를 2~4byte로 인코딩
  - 한글, 한자, 히브리어와 같은 문자들은 UTF-8에서 3~4byte를 차지함(UTF-16에서는 대부분 2byte로 인코딩)
- 장점: ASCII 문자는 1바이트로 표현, ASCII 호환
- 현대 사실상 표준 인코딩 기술
  - 1990년도 후반 ~ 2000년도 초반에 인터넷과 웹이 빠르게 성장하면서 저변 확대
  - 2008년 W3C 웹 표준에 UTF-8 채택
  - 현재 대부분의 웹 사이트와 애플리케이션에서 기본 인코딩으로 사용

**정리**

UTF-8이 현대의 사실상 표준 인코딩 기술이 된 이유
- 저장 공간 절약과 네트워크 효율성
  - UTF-8은 ASCII 문자를 포함한 많은 서양 언어의 문자에 대해 1바이트를 사용
  - 반면 UTF-16은 최소 2byte를 사용하므로 주로 ASCII 문자로 이루어진 영문 텍스트에서는 UTF-8이 2배 더 효과적
  - 데이터를 네트워크로 전달할 때는 매우 큰 효율의 차이를 보임(웹의 문서의 80%는 영어 문서)
- ASCII 호환성
  - UTF-8은 ASCII와 호환됨
  - UTF-8로 인코딩된 텍스트에서 ASCII 범위에 있는 문자는 기존 ASCII와 동일한 방식으로 처리
  - UTF-8은 이러한 시스템과의 호환성을 유지하면서도 전 세계의 모든 문자를 표현

UTF-8을 사용하자!!

> 참고: 한글 윈도우의 경우 기존 윈도우와 호환성 때문에 기본 인코딩을 MS949로 유지함
> 한글 윈도우도 기본 인코딩을 UTF-8로 변경하려고 노력중

# 문자 집합 조회

## 사용 가능한 문자 집합 조회

> encoding.AvailableCharsetsMain 참조

**이용가능한 모든 문자 집합 조회**

`CharSet.availableCharsets()`를 사용하면 이용가능한 모든 문자 집합을 조회할 수 있음

자바가 기본으로 제공하는 문자 집합과 OS가 제공하는 문자 집합을 포함

**Charset.forName()**

특정 문자 집합을 지정해서 찾을 때는 `Charset.forName(...)`을 사용

인자로 문자 집합의 이름이나 별칭을 사용하면됨, 대소문자 구분 없음

별칭은 `aliases()` 메소드를 사용하면 구할수 있음

**StandardCharsets.UTF_8**

자주 사용하는 문자 집합은 `StandardCharsets`에 상수로 지정되어 있음

```java
public final class StandardCharsets {
    public static final Charset US_ASCII = sun.nio.cs.US_ASCII.INSTANCE;
    public static final Charset ISO_8859_1 = sun.nio.cs.ISO_8859_1.INSTANCE;
    public static final Charset UTF_8 = sun.nio.cs.UTF_8.INSTANCE;
    public static final Charset UTF_16BE = new sun.nio.cs.UTF_16BE();
    public static final Charset UTF_16LE = new sun.nio.cs.UTF_16LE();
    public static final Charset UTF_16 = new sun.nio.cs.UTF_16();
}
```

**Charset.defaultCharset()**

현재 시스템에서 사용하는 기본 문자 집할을 처리

# 문자 인코딩 예제 1

`Charset`(문자 집합)을 사용해서 실제 문자 인코딩을 해봄

> EncodingMain1 참조

- 문자를 컴퓨터가 이해할 수 있는 숫자(byte)로 변경하는 것을 문자 인코딩이라 함
- `String.getByte(Charset)` 메소드를 사용하면 `String` 문자를 `byte` 배열로 변경할 수 있음
- 문자를 byte로 변경하려면 문자 집합이 필요함, 어떤 문자 집합을 참고해서 byte로 변경할지 정해야함, `String.getByte()`의 인자로 `Charset` 객체를 전달하면 됨
  - 문자 집합을 지정하지 않으면 현재 시스템에서 사용하는 기본 문자 집합을 인코딩에 사용

```bash
== ASCII 영문 처리 ==
A -> [US-ASCII] 인코딩 -> [65] 1byte
A -> [ISO-8859-1] 인코딩 -> [65] 1byte
A -> [EUC-KR] 인코딩 -> [65] 1byte
A -> [UTF-8] 인코딩 -> [65] 1byte
A -> [UTF-16BE] 인코딩 -> [0, 65] 2byte
== 한글 지원 ==
가 -> [EUC-KR] 인코딩 -> [-80, -95] 2byte
가 -> [x-windows-949] 인코딩 -> [-80, -95] 2byte
가 -> [UTF-8] 인코딩 -> [-22, -80, -128] 3byte
가 -> [UTF-16BE] 인코딩 -> [-84, 0] 2byt
```

**영문**

- US-ASCII, ISO-8859-1, EUC-KR, MS949, UTF-8은 모두 ASCII와 호환
  - 영문 A는 1byte만 사용하고, 숫자 65로 인코딩
- UTF-16은 ASCII와 호환되지 않음
  - 영문 A는 2byte를 사용하고, 숫자 [0, 65]로 인코딩

**한글**

- EUC-KR, MS949는 한글 인코딩에 2byte를 사용하고 같은 값으로 인코딩
  - EUC-KR을 확장하여 만든것이 MS949
- UTF-8은 한글 인코딩에 3byte를 사용
- UTF-16은 한글 인코딩에 2byte를 사용

**참고**

UTF_16, UTF_16BE, UTF_16LE가 있음, BE, LE는 byte의 순서의 차이

'A'를 저장한다면
- UTF_16BE: [0, 41]
- UTF_16LE: [41, 0]
- UTF_16: 인코딩한 문자가 BE, LE중어 어떤 것인지 알려주는 2byte가 앞에 추가로 붙음
- UTF_16은 잘 사용하지 않고 UTF-8은 이런 이슈가 없으니 참고

**참고**
"A"의 2byte 표현시 0 65를 가짐

BE, LE는 byte의 순서의 차이가 있음

- UTF_16BE: [0, 65]
- UTF_16LE: [65, 0]
- UTF_16: [-2, -1, 0, 65] 인코딩한 문자가 BE, LE 중 어떤 것인지 알려주는 2byte가 앞에 추가로 붙음
- UTF_16을 잘 사용하지 않고, UTF-8은 이러한 이슈가 없음

## 참고: byte 출력에 마이너스 숫자가 보이는 이유

`가`를 EUC-KR로 인코딩 시

> 가 -> [EUC-KR] 인코딩 -> [-80, -95] 2byte

- byte의 기본 개념
  - 1byte는 8개의 bit로 구성됨(예: 0000 0000)
  - 1byte로 256가지 경우를 표현할 수 있음
- 한글 '가'의 EUC-KR 인코딩
  - '가'는 EUC-KR 에서 2byte로 표현
  - 첫 번째 byte: 10110000 (10진수로 176)
  - 두 번째 byte: 10100001 (10진수로 161)
  - 따라서 '가'는 10진수로 표현하면 [176, 161]로 표현
- 자바에서 byte 표현
  - 자바에서 byte 타입은 양수와 음수를 모두 표현
  - 자바의 byte 첫 번째 비트(bit)가 0이면 양수, 1이면 음수로 간주
    - 0 ~ 127: 첫 비트가 0이면 양수로 간주, 나머지 7bit로 0부터 127까지 128가지 숫자를 표현
    - -128 ~ -1: 첫 비스가 1이면 음수로 간주, 나머지 7bit로 -128부터 -1까지 128가지 숫자를 표현 
  - 자바의 byte는 256가지 값을 표현하지만 표현 가능한 숫자의 범위는 -128 ~ 127 임
- '가'의 EUC-KR 인코딩을 자바 byte로 표현
  - 첫 번째 byte(10110000)(10진수로 176)
    - 첫 비트가 1이므로 음수로 해석
    - 자바에서 -80으로 표현
    - 자바에서 음수를 표현할 때는 2의 보수라는 계산 공식 사용
  - 두 번째 byte(10100001)(10진수로 161)
    - 첫 비트가 1이므로 음수로 해석
    - 자바에서 -95로 표현됨
- 정리
  - 자바의 byte를 사용해도 실제 메모리에 저장되는 값은 동일(10110000, 10100001)
  - 자바의 byte 타입이 첫 비트로 음수로 표현하기 때문에 화면에 보여지는 10진수 숫자마 다를 뿐임

# 문자 인코딩 예제 2

## 문자 인코딩, 디코딩

> EncodingMain2 참조

**영문 ASCII 인코딩**

```shell
A -> [US-ASCII] 인코딩 -> [65] 1byte -> [US-ASCII] 디코딩 -> A
A -> [US-ASCII] 인코딩 -> [65] 1byte -> [ISO-8859-1] 디코딩 -> A
A -> [US-ASCII] 인코딩 -> [65] 1byte -> [EUC-KR] 디코딩 -> A
A -> [US-ASCII] 인코딩 -> [65] 1byte -> [UTF-8] 디코딩 -> A
A -> [US-ASCII] 인코딩 -> [65] 1byte -> [UTF-16BE] 디코딩 -> �
A -> [US-ASCII] 인코딩 -> [65] 1byte -> [UTF-16LE] 디코딩 -> �
A -> [US-ASCII] 인코딩 -> [65] 1byte -> [UTF-16] 디코딩 -> �
```

- 영문 'A'를 인코딩하면 1byte를 사용하고 숫자 65가 됨
- 숫자 65를 디코딩하면 UTF-16을 제외하고 모두 디코딩 가능
  - UTF-16의 경우 디코딩에 실패해서 `�`라는 특수문자가 출력됨
- ASCII는 UTF-16을 제외한 대부분의 문자 집합에 호환됨

**한글 인코딩 - 기본**

```shell
가 -> [US-ASCII] 인코딩 -> [63] 1byte -> [US-ASCII] 디코딩 -> ?
가 -> [ISO-8859-1] 인코딩 -> [63] 1byte -> [ISO-8859-1] 디코딩 -> ?
가 -> [EUC-KR] 인코딩 -> [-80, -95] 2byte -> [EUC-KR] 디코딩 -> 가
가 -> [x-windows-949] 인코딩 -> [-80, -95] 2byte -> [EUC-KR] 디코딩 -> 가
가 -> [UTF-8] 인코딩 -> [-22, -80, -128] 3byte -> [EUC-KR] 디코딩 -> 媛�
```

- 한글 '가'는 ASCII, ISO-8859-1로 인코딩 불가
  - 결과가 숫자 63이 되는데 63은 ASCII로 `?`라는 뜻, 따라서 이상한 문자로 인코딩 되었다는 뜻
- EUC-KR, MS949, UTF-8, UTF-16은 한글 인코딩 디코딩이 잘 수행되는 것을 확인
  - 2byte: EUC-KR, MS949, UTF-16
  - 3byte: UTF-8
- 한글 기반 '가'는 EUC-KR, MS949 모두 같은 값을 반환하며 서로 호환됨

**한글 인코딩 - 복잡한 문자**

```shell
뷁 -> [EUC-KR] 인코딩 -> [63] 1byte -> [EUC-KR] 디코딩 -> ?
뷁 -> [x-windows-949] 인코딩 -> [-108, -18] 2byte -> [x-windows-949] 디코딩 -> 뷁
뷁 -> [UTF-8] 인코딩 -> [-21, -73, -127] 3byte -> [UTF-8] 디코딩 -> 뷁
뷁 -> [UTF-16BE] 인코딩 -> [-67, -63] 2byte -> [UTF-16BE] 디코딩 -> 뷁
```

- EUC-KR은 자주 사용하는 한글 2350개만 표현
- MS949, UTF-8, UTF-16은 모든 한글을 표현

**한글 인코딩 - 디코딩이 다른 경우**

```shell
가 -> [EUC-KR] 인코딩 -> [-80, -95] 2byte -> [x-windows-949] 디코딩 -> 가
뷁 -> [x-windows-949] 인코딩 -> [-108, -18] 2byte -> [EUC-KR] 디코딩 -> ��
가 -> [EUC-KR] 인코딩 -> [-80, -95] 2byte -> [UTF-8] 디코딩 -> ��
뷁 -> [x-windows-949] 인코딩 -> [-108, -18] 2byte -> [UTF-8] 디코딩 -> ��
뷁 -> [UTF-8] 인코딩 -> [-21, -73, -127] 3byte -> [x-windows-949] 디코딩 -> 酉�
```

- '가'와 같이 자주 사용하는 한글은 EUC-KR, MS949 서로 호환됨
- '뷁'과 같이 특수한 한글은 MS949로 인코딩 할 수 있지만 EUC-KR로 디코딩 할 수 없음
- 한글을 인코딩 할 때 UTF-8과 EUC-KR(MS949)는 서로 호환되지 않음

**영어 인코딩 - 디코딩이 다른 경우**

```shell
A -> [EUC-KR] 인코딩 -> [65] 1byte -> [UTF-8] 디코딩 -> A
A -> [x-windows-949] 인코딩 -> [65] 1byte -> [UTF-8] 디코딩 -> A
A -> [UTF-8] 인코딩 -> [65] 1byte -> [x-windows-949] 디코딩 -> A
A -> [UTF-8] 인코딩 -> [65] 1byte -> [UTF-16BE] 디코딩 -> �
```

- ASCII에 포함되는 영문은 UTF-16을 제외한 대부분의 문자 집합과 호환됨

**정리**

- ASCII 영문 인코딩: UTF-16을 제외하고 모두 호환
- 사실상 표준인 UTF-8을 사용하자

**한글이 깨지는 가장 큰 2가지 이유**

- EUC-KR(MS949), UTF-8이 서로 호환되지 않음
  - 한글이 깨지는 대부분의 문제는 UTF-8로 인코딩한 한글을 EUC-KR(MS949)로 디코딩하거나 또는 EUC-KR(MS949)로 이루어진 한글을 UTF-8로 디코딩할 때 발생
  - EUC-KR(MS949) 또는 UTF-8로 인코딩한 한글을 `ISO-8859-1`로 디코딩 할 때
    - EUC-KR(MS949) 또는 UTF-8로 인코딩한 한글을 지원하지 않는 `ISO-8859-1`로 디코딩할 때 발생